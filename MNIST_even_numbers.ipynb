{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "        a, b = itertools.tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def __init__(self):\n",
    "        self.iterations = 1000  # количество итераций для градиентного спуска\n",
    "        self.alpha = 0.1  # скорость обучения\n",
    "        self.lamda = 0.5  # параметр для регуляризации\n",
    "        self.n = 4  # слоев в нейросети\n",
    "        self.m = [28, 3, 3, 1]  # массив числа нейронов дл каждого слоя\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def deriv_sigmoid(X):\n",
    "        fx = sigmoid(X)\n",
    "        return fx * (1 - fx)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_loss(Y, theta):\n",
    "        return ((Y - theta) ** 2).mean()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(X):\n",
    "        out = np.exp(X)\n",
    "        return out/np.sum(out)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(Y, theta):\n",
    "        return -np.sum(Y * np.log(theta)) \n",
    "\n",
    "    \n",
    "    def backpropagation(self, deriv_grad_func, y, x, weights, theta, R):\n",
    "        d_ypred = -2 * (y - theta[-1])\n",
    "        sum_h = 0\n",
    "        sum_old_h = 0\n",
    "        old_w = list()\n",
    "        for i in range(len(theta) - 1, 0, -1):\n",
    "            if i == len(theta) - 1:\n",
    "                old_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * deriv_grad_func(sum_h)\n",
    "                    sum_h = 0\n",
    "            else:\n",
    "                present_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    new_w = np.sum(old_w[k])\n",
    "                    for z in range(len(old_w[k])):\n",
    "                        sum_old_h += old_w[k][z] * theta[i][z]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "                    sum_old_h = 0\n",
    "                    sum_h = 0\n",
    "                old_w = present_w\n",
    "        for k in range(len(theta[0])):\n",
    "            new_w = np.sum(old_w[k])\n",
    "            for z in range(len(old_w[k])):\n",
    "                sum_old_h += old_w[k][z] * theta[0][z]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                weights[0][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * x[k][z] * deriv_grad_func(sum_h)\n",
    "            R[0][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "            sum_old_h = 0\n",
    "            sum_h = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, grad_func, x, weights, theta, R):\n",
    "        sum_h = 0\n",
    "        for k in range(len(theta[0])):\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            theta[0][k] = grad_func(sum_h)\n",
    "            sum_h = 0\n",
    "        for i in range(1, len(theta)):\n",
    "            for k in range(len(theta[i])):\n",
    "                for z in range(len(weights[i][k])):\n",
    "                    sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                sum_h += R[i][k]\n",
    "                theta[i][k] = grad_func(sum_h)\n",
    "                sum_h = 0\n",
    "        return theta[-1]\n",
    "        \n",
    "\n",
    "    def gradient_descent(self, data, y_true, deriv_grad_func=deriv_sigmoid,\n",
    "                         grad_func=sigmoid, loss_func=mse_loss):\n",
    "        theta = [0] * self.n\n",
    "        weights = [0] * self.n\n",
    "        R = [0] * self.n\n",
    "        j = 0\n",
    "        for i in self.m:\n",
    "            theta[j] = np.random.randn(i, 1)\n",
    "            R[j] = np.full(i, 0).reshape(-1, 1)\n",
    "            j += 1\n",
    "            \n",
    "        j = 1\n",
    "        weights[0] = np.random.randn(28, self.m[0])  # первый параметр равен размерности X\n",
    "        for z1, z2 in pairwise(self.m):\n",
    "            weights[j] = np.random.randn(z1, z2)\n",
    "            j += 1\n",
    "\n",
    "        reg_theta = lambda theta, lamda, k: (lamda / len(theta)) * theta[k]\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            for k in range(len(theta[i])):  # регуляризация каждой theta\n",
    "                R[i][k] = reg_theta(theta[i], self.lamda, k)\n",
    "                \n",
    "        for iteration in range(self.iterations):  # обновление параметров\n",
    "            for x, y in zip(data, y_true):\n",
    "                y_pred = self.forward(grad_func, x, weights, theta, R)\n",
    "                self.backpropagation(deriv_grad_func, y, x, weights, theta, R)\n",
    "            if iteration % 10 == 0:\n",
    "                loss = loss_func(y_true, theta[-1])\n",
    "                print(\"Epoch %d loss: %.3f\" % (iteration, loss))\n",
    "        \n",
    "        # return theta[-1], loss_func(y_true, theta[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [3, 2, 3, 1]\n",
    "w = [0] * 4\n",
    "j = 1   \n",
    "w[0] = np.random.randn(3, m[0])\n",
    "for z1, z2 in pairwise(m):\n",
    "    w[j] = np.random.randn(z1, z2)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.42783508, -0.07674535, -0.20535591],\n",
       "        [-1.06508228,  1.05560809,  0.22989997],\n",
       "        [ 0.77365234, -0.57880178,  1.413978  ]]),\n",
       " array([[-0.38922187,  1.07445015],\n",
       "        [ 0.15722217, -0.70245049],\n",
       "        [ 1.66013803, -1.78201657]]),\n",
       " array([[ 0.3165867 , -1.48687859, -2.40134593],\n",
       "        [ 1.33489263,  1.13571113, -1.05588891]]),\n",
       " array([[-0.83096367],\n",
       "        [ 2.42073245],\n",
       "        [-1.70613436]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
