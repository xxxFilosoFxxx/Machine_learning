{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gzip\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "        a, b = itertools.tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "def extract_labels(filename, num_images):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "m = 2000\n",
    "X = extract_data('t10k-images-idx3-ubyte.gz', m, 28)\n",
    "Y = extract_labels('t10k-labels-idx1-ubyte.gz', m).reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализация данных\n",
    "X -= int(np.mean(X))\n",
    "X /= int(np.std(X))\n",
    "X = X.reshape(len(X), 28, 28)  # представление картинки 28х28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "for i in Y:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное\n",
    "        \n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sigmoid(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def deriv_sigmoid(X):\n",
    "        fx = Utils.sigmoid(X)\n",
    "        return fx * (1 - fx)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_loss(Y, theta):\n",
    "        return ((Y - theta) ** 2).mean()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(X):\n",
    "        out = np.exp(X)\n",
    "        return out/np.sum(out)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(Y, theta):\n",
    "        return -np.sum(Y * np.log(theta)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self):\n",
    "        self.iterations = 8  # количество итераций для градиентного спуска\n",
    "        self.alpha = 0.2  # скорость обучения\n",
    "        self.lamda = 0.5  # параметр для регуляризации\n",
    "        self.n = 5  # слоев в нейросети\n",
    "        self.m = [28, 14, 7, 2, 1]  # массив числа нейронов для каждого слоя\n",
    "    \n",
    "    \n",
    "    def backpropagation(self, deriv_grad_func, y, x, weights, theta, R):\n",
    "        d_ypred = -2 * (y - theta[-1][0])\n",
    "        sum_h = 0\n",
    "        sum_old_h = 0\n",
    "        old_w = list()\n",
    "        for i in range(len(theta) - 1, 0, -1):\n",
    "            if i == len(theta) - 1:\n",
    "                old_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * deriv_grad_func(sum_h)\n",
    "                    sum_h = 0\n",
    "            else:\n",
    "                present_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    new_w = np.sum(old_w[k])\n",
    "                    for z in range(len(old_w[k])):\n",
    "                        sum_old_h += old_w[k][z] * theta[i][z]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "                    sum_old_h = 0\n",
    "                    sum_h = 0\n",
    "                old_w = present_w\n",
    "        for k in range(len(theta[0])):\n",
    "            new_w = np.sum(old_w[k])\n",
    "            for z in range(len(old_w[k])):\n",
    "                sum_old_h += old_w[k][z] * theta[0][z]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                weights[0][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * x[k][z] * deriv_grad_func(sum_h)\n",
    "            R[0][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "            sum_old_h = 0\n",
    "            sum_h = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, grad_func, x, weights, theta, R):\n",
    "        sum_h = 0\n",
    "        for k in range(len(theta[0])):\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            theta[0][k] = grad_func(sum_h)\n",
    "            sum_h = 0\n",
    "        for i in range(1, len(theta)):\n",
    "            for k in range(len(theta[i])):\n",
    "                for z in range(len(weights[i][k])):\n",
    "                    sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                sum_h += R[i][k]\n",
    "                theta[i][k] = grad_func(sum_h)\n",
    "                sum_h = 0\n",
    "        return theta[-1]\n",
    "        \n",
    "        \n",
    "    def reg_theta(self, theta, k):\n",
    "        return (self.lamda / len(theta)) * theta[k]\n",
    "\n",
    "    \n",
    "    def gradient_descent(self, data, y_true, deriv_grad_func=Utils.deriv_sigmoid,\n",
    "                         grad_func=Utils.sigmoid, loss_func=Utils.mse_loss):\n",
    "        theta = [0] * self.n\n",
    "        weights = [0] * self.n\n",
    "        R = [0] * self.n\n",
    "        y_pred = np.array([])\n",
    "        old_y_pred = np.array([])\n",
    "        j = 0\n",
    "        for i in self.m:\n",
    "            theta[j] = np.random.randn(i, 1)\n",
    "            R[j] = np.full(i, 0.).reshape(-1, 1)\n",
    "            j += 1\n",
    "            \n",
    "        j = 1\n",
    "        weights[0] = np.random.uniform(-0.5, 0.5, size=(28, self.m[0]))  # первый параметр равен размерности X\n",
    "        for z1, z2 in pairwise(self.m):\n",
    "            weights[j] = np.random.uniform(-0.5, 0.5, size=(z1, z2))\n",
    "            j += 1\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            for k in range(len(theta[i])):  # регуляризация каждой theta\n",
    "                new_R = self.reg_theta(theta[i], k)\n",
    "                R[i][k] = new_R\n",
    "        for iteration in tqdm(range(self.iterations)):  # обновление параметров\n",
    "            for x, y in zip(data, y_true):\n",
    "                new_y_pred = self.forward(grad_func, x, weights, theta, R)\n",
    "                self.backpropagation(deriv_grad_func, y, x, weights, theta, R)\n",
    "                y_pred = np.append(y_pred, new_y_pred[0])\n",
    "                y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "            if iteration % 1 == 0:\n",
    "                loss = loss_func(y_true[:len(y_pred)], y_pred)\n",
    "                print(\"Epoch %d loss: %.3f\" % (iteration + 1, loss))\n",
    "                y_pred = old_y_pred\n",
    "        \n",
    "        return theta, weights, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:43<05:06, 43.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [01:25<04:19, 43.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [02:08<03:35, 43.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [02:51<02:51, 42.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [03:34<02:08, 42.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [04:16<01:25, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [04:59<00:42, 42.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [05:41<00:00, 42.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "theta, weights, R = network.gradient_descent(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "_max = 10000\n",
    "X_test = extract_data('t10k-images-idx3-ubyte.gz', _max, 28)\n",
    "Y_test = extract_labels('t10k-labels-idx1-ubyte.gz', _max).reshape(_max,1)\n",
    "\n",
    "X_test -= int(np.mean(X_test))\n",
    "X_test /= int(np.std(X_test))\n",
    "X_test = X_test.reshape(len(X_test), 28, 28)\n",
    "for i in Y_test:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7581\n",
      "Overall Accuracy: 75.81\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "accuary = 0\n",
    "for i in X_test:\n",
    "    res = network.forward(Utils.sigmoid, i, weights, theta, R)\n",
    "    if Y_test[n][0] == 1 and res[0][0] > 0.1:\n",
    "        accuary += 1\n",
    "    elif Y_test[n][0] == 0 and res[0][0] < 0.1:\n",
    "        accuary += 1\n",
    "    # print(str(Y_test[n]) + '->' + str(res))\n",
    "    n += 1\n",
    "print(accuary)\n",
    "print(\"Overall Accuracy: %.2f\" % (float(accuary/len(X_test)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
