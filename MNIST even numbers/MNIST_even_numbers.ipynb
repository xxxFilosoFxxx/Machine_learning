{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gzip\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "        a, b = itertools.tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "def extract_labels(filename, num_images):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "X = extract_data('train-images-idx3-ubyte.gz', m, 28)\n",
    "Y = extract_labels('train-labels-idx1-ubyte.gz', m).reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN9ElEQVR4nO3df6xU9ZnH8c9H2mLiJQGWwCJl19qoATbBbggSrZtuDJX1H21iSdWsrEsW/5CoiTEa9w9Rs9psVjZGkia3QaXSlZD4C2pjNaRZ3cQ0gKJiWesPVKj8WEKiEKP1wrN/3IO5xTvfucyvM9zn/UpuZuY8c+Y8mfDhnDPfOfN1RAjA+HdG3Q0A6A3CDiRB2IEkCDuQBGEHkvhGLzdmm4/+gS6LCI+2vK09u+0ltt+2/a7tO9t5LQDd5VbH2W1PkPQHSYsl7ZW0VdI1EfH7wjrs2YEu68aefaGkdyPi/Yj4k6QNkq5s4/UAdFE7YZ8lac+Ix3urZX/G9grb22xva2NbANrUzgd0ox0qfO0wPSIGJQ1KHMYDdWpnz75X0uwRj78t6eP22gHQLe2Efauk82x/x/a3JP1E0qbOtAWg01o+jI+IIdsrJf1G0gRJj0TEWx3rDEBHtTz01tLGOGcHuq4rX6oBcPog7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImWp2zG6WHChAnF+pQpU7q6/VWrVjWsDQwMFNedO3dusX711VcX6+vXr29Yu/TSS4vrDg0NFeuDg4PF+k033VSs16GtsNv+QNIRScckDUXEgk40BaDzOrFn//uIONSB1wHQRZyzA0m0G/aQ9ILt7bZXjPYE2ytsb7O9rc1tAWhDu4fxl0TEx7anS3rR9v9GxEsjnxARg5IGJcl2tLk9AC1qa88eER9XtwclPS1pYSeaAtB5LYfd9lm2J524L+mHknZ2qjEAndXOYfwMSU/bPvE6/xURz3ekq3Hm3HPPLdbPPPPMYv3yyy8v1hcvXtywNnny5OK6ixYtKtbr9OmnnxbrGzduLNYXLmx8oPnFF18U192zZ0+xvmXLlmK9H7Uc9oh4X9L8DvYCoIsYegOSIOxAEoQdSIKwA0kQdiAJR/TuS23j9Rt0zS6XfOGFF4r1iRMndrKd00azf3u33XZbsX706NGWt91saG3//v3F+uuvv97ytrstIjzacvbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wdMG3atGL97bffLta7/XPO7di9e3exfuTIkWJ93rx5DWvHjh0rrtvs0l+MjnF2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCKZs74NCh8ryWt99+e7G+dOnSYv2VV14p1u++++5ivWTv3r3F+vz55R8QbnZN+YIFjSf2vffee4vrorPYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAElzP3geaTav8ySefFOvPPfdcw9qSJUuK695yyy3F+sMPP1yso/+0fD277UdsH7S9c8SyqbZftP1Oddu/v74AQNLYDuMfk3Ty7uFOSVsi4jxJW6rHAPpY07BHxEuSDp+0+EpJ66r76yRd1eG+AHRYq9+NnxER+yQpIvbZnt7oibZXSFrR4nYAdEjXL4SJiEFJgxIf0AF1anXo7YDtmZJU3R7sXEsAuqHVsG+StKy6v0zSs51pB0C3NB1nt/2EpB9ImibpgKS7JT0jaaOkv5L0kaQfR8TJH+KN9locxnfB+vXrG9auvfba4rrNftO+9LvvknT8+PFiHb3XaJy96Tl7RFzToHRZWx0B6Cm+LgskQdiBJAg7kARhB5Ig7EASXOI6DgwMDDSsbd26tbjuBRdcUKw3G7rbsGFDsY7eY8pmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfZxbs6cOcX6a6+9Vqx//vnnxfr27duL9Zdffrlh7Z577imu28t/m+MJ4+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7MktX768WF+zZk2xPnHixJa3vXr16mL9oYceKtb37NnT8rbHM8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRdNFFFxXra9euLdbnzp3b8rY3b95crN98883F+ocfftjytk9nLY+z237E9kHbO0csW2X7j7Z3VH9XdLJZAJ03lsP4xyQtGWX5f0bEhdXfrzvbFoBOaxr2iHhJ0uEe9AKgi9r5gG6l7Teqw/wpjZ5ke4Xtbba3tbEtAG1qNew/k/RdSRdK2ifpwUZPjIjBiFgQEQta3BaADmgp7BFxICKORcRxST+XtLCzbQHotJbCbnvmiIc/krSz0XMB9Iem4+y2n5D0A0nTJB2QdHf1+EJJIekDSTdGxL6mG2OcfdyZOnVqsX799dc3rD34YMOzP0mSPepw8Vd27dpVrM+bN69YH68ajbN/YwwrXjPK4vI3KQD0Hb4uCyRB2IEkCDuQBGEHkiDsQBJc4oraDA0NFetnnFHeFx0/frxYX7p0acPaU089VVz3dMZPSQPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEk2vekNuixYtKtZvuOGGltdvNo7ezP79+4v1Z555pq3XH2/YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzj3Pz588v1letWlWsX3bZZcX6wMDAqbY0Zs2uVz906FBb62fDnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCc/TQwa9asYn3lypUNazfeeGNx3cmTJ7fUUyd89NFHxXqz7wA89thjnWsmgaZ7dtuzbf/W9i7bb9m+pVo+1faLtt+pbqd0v10ArRrLYfyQpNsiYo6kRZJusj1X0p2StkTEeZK2VI8B9KmmYY+IfRHxanX/iKRdkmZJulLSuupp6yRd1a0mAbTvlM7ZbZ8j6XuSfidpRkTsk4b/Q7A9vcE6KyStaK9NAO0ac9htD0h6UtKtEfGpPerccV8TEYOSBqvXYGJHoCZjGnqz/U0NB/2XEXFi+ssDtmdW9ZmSDnanRQCd0HTP7uFd+FpJuyJi9YjSJknLJP20un22Kx2OA2effXaxfvHFFxfra9asKdanTx/1DKondu/eXazff//9DWuPPvpocV0uUe2ssRzGXyLpHyW9aXtHtewuDYd8o+3lkj6S9OPutAigE5qGPSL+R1KjE/TyLxsA6Bt8XRZIgrADSRB2IAnCDiRB2IEkuMR1jKZNm9awtnnz5uK6559/frE+ZUp9Fwy+9957xfoDDzxQrG/YsKFY/+yzz065J3QHe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNOPvixYuL9fvuu69YnzNnTsPapEmTWuqpU7788suGtccff7y47q233lqsHz16tKWe0H/YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEmnG2a+77rpifeHChV3b9oEDB4r1559/vlgfGhoq1u+4446GtcOHDxfXRR7s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCUdE+Qn2bEm/kPSXko5LGoyIh2yvkvQvkv6veupdEfHrJq9V3hiAtkXEqLMujyXsMyXNjIhXbU+StF3SVZKWSjoaEf8x1iYIO9B9jcI+lvnZ90naV90/YnuXpFmdbQ9At53SObvtcyR9T9LvqkUrbb9h+xHbo85hZHuF7W22t7XVKYC2ND2M/+qJ9oCk/5b0bxHxlO0Zkg5JCkn3afhQ/5+bvAaH8UCXtXzOLkm2vynpV5J+ExGrR6mfI+lXEfE3TV6HsANd1ijsTQ/jbVvSWkm7Rga9+uDuhB9J2tlukwC6Zyyfxn9f0suS3tTw0Jsk3SXpGkkXavgw/gNJN1Yf5pVeiz070GVtHcZ3CmEHuq/lw3gA4wNhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiV5P2XxI0ocjHk+rlvWjfu2tX/uS6K1VneztrxsVeno9+9c2bm+LiAW1NVDQr731a18SvbWqV71xGA8kQdiBJOoO+2DN2y/p1976tS+J3lrVk95qPWcH0Dt179kB9AhhB5KoJey2l9h+2/a7tu+so4dGbH9g+03bO+qen66aQ++g7Z0jlk21/aLtd6rbUefYq6m3Vbb/WL13O2xfUVNvs23/1vYu22/ZvqVaXut7V+irJ+9bz8/ZbU+Q9AdJiyXtlbRV0jUR8fueNtKA7Q8kLYiI2r+AYfvvJB2V9IsTU2vZ/ndJhyPip9V/lFMi4o4+6W2VTnEa7y711mia8X9Sje9dJ6c/b0Ude/aFkt6NiPcj4k+SNki6soY++l5EvCTp8EmLr5S0rrq/TsP/WHquQW99ISL2RcSr1f0jkk5MM17re1foqyfqCPssSXtGPN6r/prvPSS9YHu77RV1NzOKGSem2apup9fcz8maTuPdSydNM943710r05+3q46wjzY1TT+N/10SEX8r6R8k3VQdrmJsfibpuxqeA3CfpAfrbKaaZvxJSbdGxKd19jLSKH315H2rI+x7Jc0e8fjbkj6uoY9RRcTH1e1BSU9r+LSjnxw4MYNudXuw5n6+EhEHIuJYRByX9HPV+N5V04w/KemXEfFUtbj29260vnr1vtUR9q2SzrP9HdvfkvQTSZtq6ONrbJ9VfXAi22dJ+qH6byrqTZKWVfeXSXq2xl7+TL9M491omnHV/N7VPv15RPT8T9IVGv5E/j1J/1pHDw36OlfS69XfW3X3JukJDR/WfanhI6Llkv5C0hZJ71S3U/uot8c1PLX3GxoO1syaevu+hk8N35C0o/q7ou73rtBXT943vi4LJME36IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8H+IFvgMuU9f8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "plt.imshow(X[0].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализация данных\n",
    "X -= int(np.mean(X))\n",
    "X /= int(np.std(X))\n",
    "X = X.reshape(len(X), 28, 28)  # представление картинки 28х28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "for i in Y:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное\n",
    "        \n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sigmoid(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def deriv_sigmoid(X):\n",
    "        fx = Utils.sigmoid(X)\n",
    "        return fx * (1 - fx)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_loss(Y, theta):\n",
    "        return ((Y - theta) ** 2).mean()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(X):\n",
    "        out = np.exp(X)\n",
    "        return out/np.sum(out)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(Y, theta):\n",
    "        return -np.sum(Y * np.log(theta)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self):\n",
    "        self.iterations = 5  # количество итераций для градиентного спуска\n",
    "        self.alpha = 0.2  # скорость обучения\n",
    "        self.lamda = 0.5  # параметр для регуляризации\n",
    "        self.n = 5  # слоев в нейросети\n",
    "        self.m = [28, 14, 7, 2, 1]  # массив числа нейронов для каждого слоя\n",
    "    \n",
    "    \n",
    "    def backpropagation(self, deriv_grad_func, y, x, weights, theta, R):\n",
    "        d_ypred = -2 * (y - theta[-1][0])\n",
    "        sum_h = 0\n",
    "        sum_old_h = 0\n",
    "        old_w = list()\n",
    "        for i in range(len(theta) - 1, 0, -1):\n",
    "            if i == len(theta) - 1:\n",
    "                old_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * deriv_grad_func(sum_h)\n",
    "                    sum_h = 0\n",
    "            else:\n",
    "                present_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    new_w = np.sum(old_w[k])\n",
    "                    for z in range(len(old_w[k])):\n",
    "                        sum_old_h += old_w[k][z] * theta[i][z]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "                    sum_old_h = 0\n",
    "                    sum_h = 0\n",
    "                old_w = present_w\n",
    "        for k in range(len(theta[0])):\n",
    "            new_w = np.sum(old_w[k])\n",
    "            for z in range(len(old_w[k])):\n",
    "                sum_old_h += old_w[k][z] * theta[0][z]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                weights[0][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * x[k][z] * deriv_grad_func(sum_h)\n",
    "            R[0][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "            sum_old_h = 0\n",
    "            sum_h = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, grad_func, x, weights, theta, R):\n",
    "        sum_h = 0\n",
    "        for k in range(len(theta[0])):\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            theta[0][k] = grad_func(sum_h)\n",
    "            sum_h = 0\n",
    "        for i in range(1, len(theta)):\n",
    "            for k in range(len(theta[i])):\n",
    "                for z in range(len(weights[i][k])):\n",
    "                    sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                sum_h += R[i][k]\n",
    "                theta[i][k] = grad_func(sum_h)\n",
    "                sum_h = 0\n",
    "        return theta[-1]\n",
    "        \n",
    "        \n",
    "    def reg_theta(self, theta, k):\n",
    "        return (self.lamda / len(theta)) * theta[k]\n",
    "\n",
    "    \n",
    "    def gradient_descent(self, data, y_true, deriv_grad_func=Utils.deriv_sigmoid,\n",
    "                         grad_func=Utils.sigmoid, loss_func=Utils.mse_loss):\n",
    "        theta = [0] * self.n\n",
    "        weights = [0] * self.n\n",
    "        R = [0] * self.n\n",
    "        y_pred = np.array([])\n",
    "        old_y_pred = np.array([])\n",
    "        j = 0\n",
    "        for i in self.m:\n",
    "            theta[j] = np.random.randn(i, 1)\n",
    "            R[j] = np.full(i, 0.).reshape(-1, 1)\n",
    "            j += 1\n",
    "            \n",
    "        j = 1\n",
    "        weights[0] = np.random.uniform(-0.5, 0.5, size=(28, self.m[0]))  # первый параметр равен размерности X\n",
    "        for z1, z2 in pairwise(self.m):\n",
    "            weights[j] = np.random.uniform(-0.5, 0.5, size=(z1, z2))\n",
    "            j += 1\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            for k in range(len(theta[i])):  # регуляризация каждой theta\n",
    "                new_R = self.reg_theta(theta[i], k)\n",
    "                R[i][k] = new_R\n",
    "        for iteration in tqdm(range(self.iterations)):  # обновление параметров\n",
    "            for x, y in zip(data, y_true):\n",
    "                new_y_pred = self.forward(grad_func, x, weights, theta, R)\n",
    "                self.backpropagation(deriv_grad_func, y, x, weights, theta, R)\n",
    "                y_pred = np.append(y_pred, new_y_pred[0])\n",
    "                y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "            if iteration % 1 == 0:\n",
    "                loss = loss_func(y_true[:len(y_pred)], y_pred)\n",
    "                print(\"Epoch %d loss: %.3f\" % (iteration + 1, loss))\n",
    "                y_pred = old_y_pred\n",
    "        \n",
    "        return theta, weights, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [05:39<22:39, 339.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [10:56<16:38, 332.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [15:06<10:16, 308.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [19:10<04:48, 288.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [22:39<00:00, 271.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "theta, weights, R = network.gradient_descent(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "_max = 10000\n",
    "X_test = extract_data('t10k-images-idx3-ubyte.gz', _max, 28)\n",
    "Y_test = extract_labels('t10k-labels-idx1-ubyte.gz', _max).reshape(_max,1)\n",
    "\n",
    "X_test -= int(np.mean(X_test))\n",
    "X_test /= int(np.std(X_test))\n",
    "X_test = X_test.reshape(len(X_test), 28, 28)\n",
    "\n",
    "for i in Y_test:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8064\n",
      "Overall Accuracy: 80.64\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "accuary = 0\n",
    "for i in X_test:\n",
    "    res = network.forward(Utils.sigmoid, i, weights, theta, R)\n",
    "    if Y_test[n][0] == 1 and res[0][0] > 0.1:\n",
    "        accuary += 1\n",
    "    elif Y_test[n][0] == 0 and res[0][0] < 0.1:\n",
    "        accuary += 1\n",
    "    # print(str(Y_test[n]) + '->' + str(res))\n",
    "    n += 1\n",
    "print(accuary)\n",
    "print(\"Overall Accuracy: %.2f\" % (float(accuary/len(X_test)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
